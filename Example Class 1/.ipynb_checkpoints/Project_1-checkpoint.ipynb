{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787d6254",
   "metadata": {},
   "source": [
    "# Project 1: Integration of Mergesort & Insertion Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf6ea27",
   "metadata": {},
   "source": [
    "In Mergesort, when the sizes of subarrays are small, the overhead of many recursive\n",
    "calls makes the algorithm inefficient. Therefore, in real use, we often combine\n",
    "Mergesort with Insertion Sort to come up with a hybrid sorting algorithm for better\n",
    "efficiency. The idea is to set a small integer S as a threshold for the size of subarrays.\n",
    "Once the size of a subarray in a recursive call of Mergesort is less than or equal to S,\n",
    "the algorithm will switch to Insertion Sort, which is efficient for small-sized input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029ecaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "import random\n",
    "import time\n",
    "from typing import List, TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ee62b",
   "metadata": {},
   "source": [
    "(a) Algorithm implementation: Implement the above hybrid algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9076853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def __init__(self, merge_sort_threshold: int):\n",
    "        self.merge_sort_threshold: int = merge_sort_threshold\n",
    "\n",
    "    def sortArray(self, nums: List[int]) -> List[int]:\n",
    "        self.arr = nums\n",
    "        self.mergeSort(0, len(nums) - 1)\n",
    "        return self.arr\n",
    "\n",
    "    def insertionSort(self, start_idx: int, end_idx: int):\n",
    "        if end_idx - start_idx < 1:\n",
    "            return\n",
    "\n",
    "        for current_idx in range(start_idx, end_idx+1):\n",
    "            current_value = self.arr[current_idx]\n",
    "            previous_idx = current_idx - 1\n",
    "            while previous_idx >= 0 and current_value < self.arr[previous_idx]:\n",
    "                self.arr[previous_idx+1] = self.arr[previous_idx]\n",
    "                previous_idx -= 1\n",
    "            self.arr[previous_idx+1] = current_value\n",
    "\n",
    "        return\n",
    "\n",
    "    def mergeSort(self, start_idx: int, end_idx: int):\n",
    "        if end_idx - start_idx < self.merge_sort_threshold:\n",
    "            self.insertionSort(start_idx, end_idx)\n",
    "            return\n",
    "\n",
    "        mid_idx = (start_idx + end_idx) // 2\n",
    "        self.mergeSort(start_idx, mid_idx)\n",
    "        self.mergeSort(mid_idx + 1, end_idx)\n",
    "        self.mergeArray(start_idx, mid_idx, end_idx)\n",
    "\n",
    "    def mergeArray(self, start_idx: int, mid_idx: int, end_idx: int):\n",
    "        left_part = self.arr[start_idx:mid_idx + 1]\n",
    "        right_part = self.arr[mid_idx + 1:end_idx + 1]\n",
    "\n",
    "        left_idx = 0\n",
    "        right_idx = 0\n",
    "        sorted_idx = start_idx\n",
    "\n",
    "        while left_idx < len(left_part) and right_idx < len(right_part):\n",
    "            if left_part[left_idx] <= right_part[right_idx]:\n",
    "                self.arr[sorted_idx] = left_part[left_idx]\n",
    "                left_idx += 1\n",
    "            else:\n",
    "                self.arr[sorted_idx] = right_part[right_idx]\n",
    "                right_idx += 1\n",
    "            sorted_idx += 1\n",
    "\n",
    "        while left_idx < len(left_part):\n",
    "            self.arr[sorted_idx] = left_part[left_idx]\n",
    "            left_idx += 1\n",
    "            sorted_idx += 1\n",
    "\n",
    "        while right_idx < len(right_part):\n",
    "            self.arr[sorted_idx] = right_part[right_idx]\n",
    "            right_idx += 1\n",
    "            sorted_idx += 1\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1eaca",
   "metadata": {},
   "source": [
    "(b) Generate input data: Generate arrays of increasing sizes, in a range from\n",
    "1,000 to 10 million. For each of the sizes, generate a random dataset of integers\n",
    "in the range of [1, â€¦, x], where x is the largest number you allow for your\n",
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2a092",
   "metadata": {},
   "source": [
    "(c) Analyze time complexity: Run your program of the hybrid algorithm on the\n",
    "datasets generated in Step (b). Record the number of key comparisons\n",
    "performed in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed9b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insufficient memory to store all datasets\n",
    "# DATASETS_PER_SIZE: int = 3\n",
    "# DATASET_MIN_SIZE = 1000\n",
    "# DATASET_MAX_SIZE = int(1e7+1)\n",
    "\n",
    "# class TestDataset(BaseModel):\n",
    "#     size: int\n",
    "#     datasets: List[List[int]] = Field(..., min_items=DATASETS_PER_SIZE, max_items=DATASETS_PER_SIZE)\n",
    "        \n",
    "# #     @field_validator(\"datasets\")\n",
    "# #     @classmethod\n",
    "# #     def check_num_datasets(cls, datasets, values):\n",
    "# #         if len(datasets) != DATASETS_PER_SIZE:\n",
    "# #             raise ValueError(f\"Required {DATASETS_PER_SIZE} datasets, got {len(datasets)}\")\n",
    "# #         return datasets\n",
    "    \n",
    "#     @field_validator(\"datasets\")\n",
    "#     @classmethod\n",
    "#     def check_dataset_size(cls, datasets, values):\n",
    "#         size = values.data.get(\"size\")\n",
    "#         if size:\n",
    "#             for dataset in datasets:\n",
    "#                 if len(dataset) != size:\n",
    "#                     raise ValueError(f\"Each dataset must have {size} elements, got {len(dataset)}\")\n",
    "#         return datasets\n",
    "\n",
    "# DATASETS: List[TestDataset] = []\n",
    "\n",
    "# for dataset_size in range(DATASET_MIN_SIZE, DATASET_MAX_SIZE):\n",
    "#     DATASETS.append(\n",
    "#         TestDataset(\n",
    "#             size=dataset_size,\n",
    "#             datasets=[\n",
    "#                 [random.randint(1, DATASET_MAX_SIZE) for _ in range(dataset_size)]\n",
    "#                 for _ in range(DATASETS_PER_SIZE)\n",
    "#             ]\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34604f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceData(BaseModel):\n",
    "    dataset_size: int\n",
    "    insert_sort_threshold: int = Field(..., ge=1)\n",
    "    time: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b254adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_MIN_SIZE = 1000\n",
    "# DATASET_MAX_SIZE = 1001 # int(1e7+1)\n",
    "# RUNS_PER_SIZE: int = 1\n",
    "\n",
    "# performance_data: List[PerformanceData] = []\n",
    "    \n",
    "# for dataset_size in range(DATASET_MIN_SIZE, DATASET_MAX_SIZE):\n",
    "#     for test_run in range(RUNS_PER_SIZE):\n",
    "#         dataset = [random.randint(1, DATASET_MAX_SIZE) for _ in range(dataset_size)]\n",
    "#         for insert_sort_threshold in range(1, 1001):\n",
    "#             solution = Solution(insert_sort_threshold)\n",
    "#             start_time = time.perf_counter()\n",
    "#             solution.sortArray(dataset)\n",
    "#             elapsed_time = time.perf_counter() - start_time\n",
    "            \n",
    "#             performance_data.append(\n",
    "#                 PerformanceData(\n",
    "#                     dataset_size=dataset_size,\n",
    "#                     insert_sort_threshold=insert_sort_threshold,\n",
    "#                     time=elapsed_time\n",
    "#                 )\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11239d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_MIN_SIZE = 1000\n",
    "DATASET_MAX_SIZE = int(1e7+1)\n",
    "RUNS_PER_SIZE: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb14a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(dataset_size: int):\n",
    "    performance_data: List[PerformanceData] = []\n",
    "    \n",
    "    for test_run in range(RUNS_PER_SIZE):\n",
    "        dataset = [random.randint(1, DATASET_MAX_SIZE) for _ in range(dataset_size)]\n",
    "        for insert_sort_threshold in range(1, 1001):\n",
    "            solution = Solution(insert_sort_threshold)\n",
    "            start_time = time.perf_counter()\n",
    "            solution.sortArray(dataset)\n",
    "            elapsed_time = time.perf_counter() - start_time\n",
    "            \n",
    "            performance_data.append(\n",
    "                PerformanceData(\n",
    "                    dataset_size=dataset_size,\n",
    "                    insert_sort_threshold=insert_sort_threshold,\n",
    "                    time=elapsed_time\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return performance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data: List[PerformanceData] = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    performance_data.extend(\n",
    "        executor.map(\n",
    "            test_dataset,\n",
    "            range(DATASET_MIN_SIZE, DATASET_MAX_SIZE)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09131f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([data.model_dump() for data in performance_data[0]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8033af",
   "metadata": {},
   "source": [
    "i. With the value of S fixed, plot the number of key comparisons over\n",
    "different sizes of the input list n. Compare your empirical results with\n",
    "your theoretical analysis of the time complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019adc3a",
   "metadata": {},
   "source": [
    "ii. With the input size n fixed, plot the number of key comparisons over\n",
    "different values of S. Compare your empirical results with your\n",
    "theoretical analysis of the time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef6793",
   "metadata": {},
   "source": [
    "iii. Using different sizes of input datasets, study how to determine an\n",
    "optimal value of S for the best performance of this hybrid algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
